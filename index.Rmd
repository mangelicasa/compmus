---
title: "My teenage years in music"
author: "Angélica Saglimbeni"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
    source: https://github.com/mangelicas/compmus/blob/main/index.Rmd
    theme:
      heading_font:
        google: 
          family: Rajdhani
          wght: 700
      base_font:
        google: Fira Sans
      code_font:
        google: Fira Mono
      bg: "#FFFFFF"
      fg: "#212529" 
      primary: "#FF69B4"
      secondary: "#39d7b8"
      success: "#39d7b8"
      danger: "#fa5577"
      warning: "#ffb14c"
      info: "#0cc7f1"
---

```{r, setup}
library(tidyverse)
library(tidymodels)
library(plotly)
library(heatmaply)
library(protoclust)
library(cowplot)
library(spotifyr)
library(compmus)
```

### Tempo for growing plants

```{r}
plantasia <- get_tidy_audio_analysis("4CyTrR4c13d57jCVstfS8T")
```

```{r}
plantasia |>
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

***
During the lockdown for COVID19, I got really into music for growing plants. This ended up being reflected in my 2020 Wrapped. With the example of 
[Plantasia](https://open.spotify.com/intl-es/track/2XV5CUyw7gPVi18d718D4f?si=e5a10490b1f7464d) I was surprised to see the average tempo is 350 bpm, which really surprised me. It seems tho that it is just taking multiples of the actual tempo. The actual tempo would most likely be 88bpm, which is closer to a slower tempo that I expected for music for growing plants.

### Introduction

For my corpus I am prospecting into teenage years. For this, I will be analyzing my Spotify Wrapped playlists from the years 2016 to 2023. As I approach my 20th birthday, this analysis serves as a reflective exploration of the music, emotions, and memories that defined my adolescence.

By examining the music I listen to, I aim to explore the evolution of my musical tastes, emotional landscapes, and life experiences throughout my teenage years. Some questions I could answer are: did the pandemic change my music taste? How does falling in love change my music listening?

Some limitations of this study are that especially in the first years Spotify Wrapped may not be completely representative as I would use other platforms to listen to music.

Regarding genre, I think there will be a common factor in all the playlists: Pop music. This might be especially prevalent in 2016 as I was not actively trying to discover other genres. A special case is 2017. I remember I started to like Lofi a lot but after a while, I stopped listening to it so it might be reflected in energy or danceability measures.


***

Here is my 2017 Spotify Wrapped:

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1E9VL5ueCeO5ph?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>


### The key to my heart

```{r}
wrapped_2016 <- get_playlist_audio_features("","37i9dQZF1Cz0jkfxGY4C8b")
wrapped_2017 <- get_playlist_audio_features("", "37i9dQZF1E9VL5ueCeO5ph")
wrapped_2018 <- get_playlist_audio_features("", "37i9dQZF1EjyqcANxerWJE")
wrapped_2019 <- get_playlist_audio_features("", "37i9dQZF1Etm167EF3Mo3c")
wrapped_2020 <- get_playlist_audio_features("", "37i9dQZF1EMg5lB7AvOgEc")
wrapped_2021 <- get_playlist_audio_features("", "45OyPM8dShcC7b029GQlQz")
wrapped_2022 <- get_playlist_audio_features("", "3DhWDsDm1dtTyhSVfVRrKA")
wrapped_2023 <- get_playlist_audio_features("", "1G5Xi8w1k6riJpEdO4oBfp")
```

```{r}
wrapped_2016 <- wrapped_2016[!duplicated(wrapped_2016), ]

```

```{r}
wrapped <-
  bind_rows(
    wrapped_2016 |> mutate(category = "2016"),
    wrapped_2017 |> mutate(category = "2017"),
    wrapped_2018 |> mutate(category = "2018"),
    wrapped_2019 |> mutate(category = "2019"),
    wrapped_2020 |> mutate(category = "2020"),
    wrapped_2021 |> mutate(category = "2021"),
    wrapped_2022 |> mutate(category = "2022"),
    wrapped_2023 |> mutate(category = "2023"),
  )
```


```{r}
key_labels <- c("C", "C♯/D♭", "D", "D♯/E♭", "E", "F", "F♯/G♭", "G", "G♯/A♭", "A", "A♯/B♭", "B")

key_hist <- ggplot(wrapped, aes(x = factor(key, labels = key_labels), fill = category)) +
  geom_bar(stat = "count", position = "identity", alpha = 0.7) +
  facet_wrap(~ category, nrow = 3, scales = "free_x") +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "PiYG") +
  labs(title = "Histogram of Keys of Songs for Each Year",
       x = "Key",
       y = "Frequency") +
  theme_minimal() +
  theme(
    # Adjusting plot size
    plot.title = element_text(size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    strip.text = element_text(size = 14),
    panel.spacing.x = unit(2, "lines"), # Adjust spacing between facets
    strip.background = element_blank(), # Remove strip background
    strip.placement = "outside", # Place strip text outside the plot area
    strip.text.x = element_text(hjust = 0) # Adjust horizontal placement of strip text
  )

key_hist 

```

***
It seems like the most frequent key on my favourite songs is C, which makes sense as its the most common key in pop musi.


### Does growing older make you listen to calmer music?

```{r}
energy_gg <- wrapped |>
  ggplot(aes(x = category, y = energy)) +
  geom_boxplot(aes(fill = category)) +
  theme(legend.position = "none") +
  scale_fill_brewer(palette="PiYG") +
  labs(
    x = "year",
    y = "energy",
    title = "As I grow older I listen to less energetic music",
    subtitle = "Energy in music thorughout the years",
    caption = "Data from Spotify Wrapped"
  ) 
ggplotly(energy_gg)
```

***

As we can see in the graph I've moved over to music with less energetic sound. This may be because as I keep growing older I prefer sound that is calmer. In addition it seems like 2016 is specially energetic. This might be because when I started using Soptify/listening to music I only listened to pop music which is usually energetic. 

### Rediscovering a song through a remix

```{r}
## Original
idc <-
  get_tidy_audio_analysis("6y6jbcPG4Yn3Du4moXaenr") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
## Remix
idc_remix <-
  get_tidy_audio_analysis("1wsZ0cp5He4Wm4yohNjwIs") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
```

```{r}
compmus_long_distance(
  idc |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  idc_remix |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  geom_vline(xintercept = 50, colour = "pink") +
  geom_vline(xintercept = 100, colour = "pink") +
  labs(x = "Original",
       y = "Remix",
       title = "How similar are the chromas?",
       caption = "Data from Spotify Wrapped") +
  scale_fill_viridis_c(guide = NULL)
```


***

When looking through all the songs from all the years I found out a [song](https://open.spotify.com/intl-es/track/6y6jbcPG4Yn3Du4moXaenr?si=1ccc365a763b4e35) and its [remix](https://open.spotify.com/intl-es/track/1wsZ0cp5He4Wm4yohNjwIs?si=614241e7ec424b23) in different years: 2017 and 2021.

I wanted to find it how similar the time frames were. And, as we can see, thay are almost complete different, except the segment between the lines.

### Two songs in one

```{r, echo = FALSE, message = FALSE}
hfl <-
  get_tidy_audio_analysis("1Dp7JGFNjvg8Nk0CtMCcnr") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  hfl |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  hfl |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 220, colour = "pink") +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

***
One of the coolest things I've found in pop music albums is tracks that include two songs inside it. These are curious to me because I never really understood how thay would decide on merging these tracks. Is it beacause they are similar?

This is the case of  [Hard Feelings/Loveless](https://open.spotify.com/intl-es/track/1Dp7JGFNjvg8Nk0CtMCcnr?si=424b5686d0714e12), a song that has a appeared in multiple of my Spotify Wrapped. The pink line shows the beginning of the transition to loveless. The transition begins with silence which is why the section is yellow/different.

### An emotional rollercoaster
```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )
```


```{r, echo = FALSE}
smb <- get_tidy_audio_analysis("3nfMOTjl5Ts1GZScRKuQnF") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches = map(segments,
                  compmus_summarise, pitches,
                  method = "mean", norm = "manhattan")
  )

smb |> 
  compmus_match_pitch_template(chord_templates, "euclidean", "manhattan") |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

***
During some of my teenage years I did Musical Theatre. In 2020 we performed the musical Legally Blonde, which due to practising also appeared in my Spotify wrapped that year. I will be analysing my favourite song in the musical:[So Much Better](https://open.spotify.com/intl-es/track/3nfMOTjl5Ts1GZScRKuQnF?si=2928dbd0923940ae). I have this memory of my teacher explaining that the song had 10 key changes to reflect the rollercoaster of emotions Elle (the protagosnist) was going through.